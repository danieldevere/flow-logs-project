# Dan DeVere (ddevere) Final Project

## Design
* Data Source
  * AWS Puts Virtual Private Cloud flowlog data into S3 bucket automatically
* Batch Layer
  1. Use Hive to specify an external table (flow_logs_raw) for the datafiles using OpenCSVSerde and location inside the S3 bucket (AWS allows this, I also experimented with putting the data into hdfs but that adds an unnecessary step)
  2. Use Hive to move the data into an Orc table (flow_logs) with the same schema like we did with flight data so our other queries can be faster.
  3. Add the data to another table (ip_traffic) which transforms the data from src, dest, bytes to ip, inbytes, outbytes. This is just an intermediate step toward the target data format.
  4. Use Map Reduce to read the orc files (had to figure that out) and transform ip_traffic into ip_traffic_by_minute in Thrift format. I used Thrift because I had trouble writing a new orc table in map reduce. 
  5. Use Hive to specify the Thrift data generated by map reduce as a new table (ip_traffic_by_minute) using the ThriftDeserializerSerde.
  6. Use Hive to create a new schema (Hive: ip_traffic_by_minute_hbase, Hbase: ip_traffic_by_minute) for an HBase table where each row is a single IP address and each column qualifier is the unix minute (minute since Jan 1, 1970). I used the datapoints as the column families. (inBytes, outBytes, inCount, outCount)
  7. Use Hive to insert the data from ip_traffic_by_minute into ip_traffic_by_minute_hbase. Discovered the use of the Hive map() function which worked really well for this.
  8. Use Hive to create a top 500 ip addresses table in hbase for easier searching on front end.
* Speed layer
  * I created another Hbase table called ip_traffic_by_minute_speed with the same column families, but it has 100 allowed versions. This means that any rows with more than 100 versions the oldest version will be deleted on an insert.
  * I wrote an AWS Lambda function that listens for new flow log files in S3 and parses and inserts them into hbase using the hbase-rest api I wrote.
  * Each time we need to know the traffic for a given IP Address we search the ip_traffic_by_minute hbase table. We then search ip_traffic_by_minute_speed for the same query, but for the timerange of most recent batch start until now. We then aggregate all the inserts since the last batch and add it to the batch data and then serve it to the front end. 
* Serving layer
  * I wrote a new hbase-rest api using Spring Boot that mostly replicates the functionality of the standard hbase-rest server. I had to do this because I was having trouble with hbase versions in my AWS cluster and hbase-rest wasn't working properly. 
  * I wrote a simple website with a Spring Boot server and Thymeleaf that will search for and display traffic from a single or multiple ip addresses on a graph created with Chart.js. The backend adds the speed and batch layer data together by specifying an Hbase timerange for the query. It uses a timerange output by the batch layer so that it can aggregate all new hbase data in the speed table since the batch. 

This ended up being quite a project to do, but one of the benefits was that running map reduce jobs in my EMR cluster actually produced a significant quantity of flow data.

## View the Web App
* URL: http://ec2-54-86-59-74.compute-1.amazonaws.com


## GitLab Repositories: 
* IpAddressByMinute (Map Reduce job for step 4 above)
* LogMonitor (AWS Lambda function that parses and inserts new flow data in speed layer)
* hbase-rest (My hbase-rest api that I wrote because I couldn't get the built in one to work)
* network-flow (Front end server that queries hbase for data and returns them to the front end which is in src/main/resources/templates and src/main/resources/static)
* scripts
  * install.sh (install script for all the services running on the EMR cluster)
  * hbase.txt (creates the hbase tables used later on)
  * batch.sh (runner script for the batch layer)
  * flow_logs.hql (Hive schemas for the tables before the MapReduce job)
  * batch.hql (Hive inserts for before the MapReduce job)
  * hbase.hql (creates and does inserts for things after the MapReduce job)
  * hbase_swap_tables.txt (this swaps the hbase speed table with the batch table)
  * cleanup.hql (cleans up the Hive tables before the next batch)

